{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting path for the relevant locations\n",
    "\n",
    "current_dir = os.getcwd()                      # current working directory\n",
    "parent_dir = os.path.dirname(current_dir)      # parent directory\n",
    "data_set = parent_dir+'/data'                  # setting the path for data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the datasets and removing the 'Cost of Construction' feature as it doesn't give well separated classes\n",
    "train = pd.read_csv(data_set + '/ClassificationTrain.csv').drop(['Cost'], axis = 1)\n",
    "test = pd.read_csv(data_set + '/ClassificationTest.csv').drop(['Cost'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Including the 'Cost of Maintainence' feature which gives well separated classes\n",
    "df = pd.read_csv(data_set + '/Cost_of_maintainence.csv')\n",
    "costMaintainence = df.groupby('District')['No. of Dugwells according to the annual cost of maintenance - Upto Rs. 1000',\n",
    "       'No. of Dugwells according to the annual cost of maintenance - Rs.1000 to 10000 ',\n",
    "       'No. of Dugwells according to the annual cost of maintenance - Rs.10000 to 50000',\n",
    "       'No. of Dugwells according to the annual cost of maintenance - Rs.50000 to 100000',\n",
    "       'No. of Dugwells according to the annual cost of maintenance - More than Rs. 100000'].sum()\n",
    "costMaintainence['total'] = costMaintainence['No. of Dugwells according to the annual cost of maintenance - Upto Rs. 1000'] + costMaintainence['No. of Dugwells according to the annual cost of maintenance - Rs.1000 to 10000 '] + costMaintainence['No. of Dugwells according to the annual cost of maintenance - Rs.10000 to 50000'] + costMaintainence['No. of Dugwells according to the annual cost of maintenance - Rs.50000 to 100000'] + costMaintainence['No. of Dugwells according to the annual cost of maintenance - More than Rs. 100000']  \n",
    "costMaintainence['total_cost'] = 1000*costMaintainence['No. of Dugwells according to the annual cost of maintenance - Upto Rs. 1000'] + 5500*costMaintainence['No. of Dugwells according to the annual cost of maintenance - Rs.1000 to 10000 '] + 30000*costMaintainence['No. of Dugwells according to the annual cost of maintenance - Rs.10000 to 50000'] + 75000*costMaintainence['No. of Dugwells according to the annual cost of maintenance - Rs.50000 to 100000'] + 100000*costMaintainence['No. of Dugwells according to the annual cost of maintenance - More than Rs. 100000']\n",
    "costMaintainence['avg_cost'] = costMaintainence['total_cost']/costMaintainence['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Including the 'Mechanical Break Down - No.' feature to get better classes\n",
    "df1 = pd.read_csv(data_set + '/Constraints.csv')\n",
    "breakdown = df1.groupby('District')['Mechanical Break Down - No.'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging the train antest datasets with the new features\n",
    "trainBreakdown = train.merge(breakdown, on = 'District')\n",
    "trainUpdated = trainBreakdown.merge(costMaintainence['avg_cost'], on = 'District')\n",
    "testBreakdown = test.merge(breakdown, on = 'District')\n",
    "testUpdated = testBreakdown.merge(costMaintainence['avg_cost'], on = 'District')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the 'Mechanical Break Down - No.' feature\n",
    "max_breakdown = trainUpdated['Mechanical Break Down - No.'].max()\n",
    "min_breakdown = trainUpdated['Mechanical Break Down - No.'].min()\n",
    "diff = max_breakdown - min_breakdown\n",
    "trainUpdated['Mechanical Break Down - No.'] = (trainUpdated['Mechanical Break Down - No.']-min_breakdown)/diff\n",
    "max_breakdown = testUpdated['Mechanical Break Down - No.'].max()\n",
    "min_breakdown = testUpdated['Mechanical Break Down - No.'].min()\n",
    "diff = max_breakdown - min_breakdown\n",
    "testUpdated['Mechanical Break Down - No.'] = (testUpdated['Mechanical Break Down - No.']-min_breakdown)/diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Binning the 'Cost of maintainence feature' into 2 classes: <7500 and >7500 i.e. low cost and high cost\n",
    "bins = [0, 7500]\n",
    "names = ['<7500', '>7500']\n",
    "d = dict(enumerate(names, 1))\n",
    "trainUpdated['Cost_Class'] = np.vectorize(d.get)(np.digitize(trainUpdated['avg_cost'], bins))\n",
    "testUpdated['Cost_Class'] = np.vectorize(d.get)(np.digitize(testUpdated['avg_cost'], bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labelling low cost class as 0 and high cost class as 1\n",
    "trainFinal = trainUpdated.replace('<7500',0).replace('>7500',1).drop(['avg_cost'], axis = 1)\n",
    "testFinal = testUpdated.replace('<7500',0).replace('>7500',1).drop(['avg_cost'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the mean and standard deviation for each feature in each class\n",
    "train_0 = trainFinal.loc[trainFinal['Cost_Class'] == 0].drop(['Cost_Class','District'], axis = 1)\n",
    "train_1 = trainFinal.loc[trainFinal['Cost_Class'] == 1].drop(['Cost_Class','District'], axis = 1)\n",
    "stats_0 = []\n",
    "stats_1 = []\n",
    "for (columnName, columnData) in train_0.iteritems():\n",
    "    column_stat = [np.mean(columnData), np.std(columnData)]\n",
    "    stats_0.append(column_stat)\n",
    "for (columnName, columnData) in train_1.iteritems():\n",
    "    column_stat = [np.mean(columnData), np.std(columnData)]\n",
    "    stats_1.append(column_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcualting probablility of class 0 and class 1\n",
    "p_0 = float(len(train_0))/len(trainFinal)\n",
    "p_1 = float(len(train_1))/len(trainFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find the probabilty of a test point belonging to class 0\n",
    "def p0_x(stats_0, x, p_0):\n",
    "    px_0 = 1\n",
    "    j=0\n",
    "    for i in stats_0:\n",
    "        px_0 *= stats.norm.pdf(x[j], i[0], i[1])\n",
    "        j+=1\n",
    "    px_0 *= p_0\n",
    "    return px_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function to find the probabilty of a test point belonging to class 1\n",
    "def p1_x(stats_1, x, p_1):\n",
    "    px_1 = 1\n",
    "    j=0\n",
    "    for i in stats_1:\n",
    "        px_1 *= stats.norm.pdf(x[j], i[0], i[1])\n",
    "        j+=1\n",
    "    px_1 *= p_1\n",
    "    return px_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.823529\n",
      "Recall = 0.913043\n",
      "F1 score = 0.865979\n"
     ]
    }
   ],
   "source": [
    "#Testing the developed model on test data. F1 score is used as a measure of accuracy of the classifer. \n",
    "testData = testFinal.drop(['Cost_Class','District'],axis = 1).to_numpy()\n",
    "testDataClass = testFinal['Cost_Class'].copy().to_numpy()\n",
    "truePredicted = 0\n",
    "truePositive = 0\n",
    "totalTruePositive = 0\n",
    "for i in range(len(testData)):\n",
    "    p0 = p0_x(stats_0, testData[i], p_0)\n",
    "    p1 = p1_x(stats_1, testData[i], p_1)\n",
    "    if p0>p1:\n",
    "        predictedClass = 0\n",
    "    else:\n",
    "        predictedClass = 1\n",
    "    if predictedClass==testDataClass[i]:\n",
    "        truePredicted +=1\n",
    "    if predictedClass== testDataClass[i] and predictedClass ==0:\n",
    "        truePositive +=1\n",
    "    if testDataClass[i]==0:\n",
    "        totalTruePositive +=1\n",
    "precision = float(truePositive)/truePredicted\n",
    "recall = float(truePositive)/totalTruePositive\n",
    "f1_score = 2*precision*recall/(precision+recall)\n",
    "print(\"Precision = %f\" %precision)\n",
    "print(\"Recall = %f\" %recall)\n",
    "print(\"F1 score = %f\" %f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
